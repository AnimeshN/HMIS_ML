{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 33,
   "id": "fce1a6c9",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "from statsmodels.tsa.stattools import adfuller\n",
    "from statsmodels.graphics.tsaplots import plot_acf, plot_pacf\n",
    "from statsmodels.tsa.arima.model import ARIMA\n",
    "from statsmodels.tsa.holtwinters import ExponentialSmoothing\n",
    "\n",
    "from sklearn.metrics import mean_squared_error\n",
    "from typing import Optional, Tuple\n",
    "from pmdarima.arima.utils import ndiffs  # Instead of 'pmdarima.utils'\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "id": "bbcf32f1",
   "metadata": {},
   "outputs": [],
   "source": [
    "from abc import ABC, abstractmethod\n",
    "import pandas as pd\n",
    "\n",
    "class BaseTimeSeriesModel(ABC):\n",
    "    def __init__(self, file_path: str, value_col: str, selected_district:str, test_size: float = 0.2):\n",
    "\n",
    "        self.data = pd.read_csv(file_path)\n",
    "        self.data = self.data[(self.data['indicator_type'] == 'Total [(A+B) or (C+D)]')]\n",
    "        self.data['date'] = pd.to_datetime(self.data['date'])\n",
    "        self.data = self.data.set_index('date')\n",
    "        self.data.index = pd.DatetimeIndex(self.data.index)\n",
    "        # self.data = self.data.asfreq('MS')  # 'MS' = Month Start\n",
    "        self.data = self.data[self.data['district'] == selected_district]\n",
    "        self.data.sort_index(inplace=True)\n",
    "        self.series = self.data[value_col]\n",
    "        self.series = self.series.asfreq('MS')\n",
    "\n",
    "        self.test_size = test_size\n",
    "        self.train = None\n",
    "        self.test = None\n",
    "        self.model = None\n",
    "        self.results = {}\n",
    "\n",
    "    def print_df(self):\n",
    "        print(\"First 5 rows:\")\n",
    "        print(self.data.head())\n",
    "        print(f\"\\nData shape: {self.series.shape}\")\n",
    "        print(f\"\\nMissing values:\\n{self.data.isnull().sum()}\")\n",
    "        print(f\"\\nData types:\\n{self.data.dtypes}\")\n",
    "        print(f\"\\nSelected value column: {self.series.name}\")\n",
    "\n",
    "    def split_data(self):\n",
    "        \"\"\"Split before any preprocessing\"\"\"\n",
    "        split_idx = int(len(self.series) * (1 - self.test_size))\n",
    "        self.full_series = self.series.copy()  # Store original\n",
    "        self.train = self.series[:split_idx]\n",
    "        self.test = self.series[split_idx:]\n",
    "\n",
    "    def print_train_test(self):\n",
    "        print(\"Train Data:\")\n",
    "        print(self.train.head())\n",
    "        print(f\"Train shape: {self.train.shape}\\n\")\n",
    "        print(\"Test Data:\")\n",
    "        print(self.test.head())\n",
    "        print(f\"Test shape: {self.test.shape}\\n\")\n",
    "\n",
    "    @abstractmethod\n",
    "    def fit_model(self, **kwargs):\n",
    "        pass\n",
    "\n",
    "    @abstractmethod\n",
    "    def forecast(self, steps: int):\n",
    "        pass\n",
    "\n",
    "    # def evaluate(self, forecast: pd.Series):\n",
    "    #     from sklearn.metrics import mean_squared_error\n",
    "    #     return mean_squared_error(self.test, forecast, squared=False)\n",
    "    \n",
    "\n",
    "    def evaluate(self, forecast: pd.Series):\n",
    "        from sklearn.metrics import mean_absolute_error, mean_absolute_percentage_error\n",
    "        \n",
    "        return {\n",
    "            'RMSE': mean_squared_error(self.test, forecast, squared=False),\n",
    "            'MAE': mean_absolute_error(self.test, forecast),\n",
    "            'MAPE': mean_absolute_percentage_error(self.test, forecast)\n",
    "        }\n",
    "    \n",
    "\n",
    "    def plot_results(self, forecast_series: pd.Series, \n",
    "                   lower: Optional[pd.Series] = None, \n",
    "                   upper: Optional[pd.Series] = None):\n",
    "        \"\"\"\n",
    "        Visualize training, test and forecast data\n",
    "        :param forecast_series: Predicted values\n",
    "        :param lower: Optional lower confidence interval\n",
    "        :param upper: Optional upper confidence interval\n",
    "        \"\"\"\n",
    "        plt.figure(figsize=(12, 6))\n",
    "        plt.plot(self.train, label='Training Data')\n",
    "        plt.plot(self.test, label='Actual Values', alpha=0.7)\n",
    "        plt.plot(forecast_series, label='Forecast', color='red', linestyle='--')\n",
    "        \n",
    "        if lower is not None and upper is not None:\n",
    "            plt.fill_between(forecast_series.index,\n",
    "                            lower,\n",
    "                            upper,\n",
    "                            color='pink', alpha=0.3)\n",
    "            \n",
    "        plt.title(f'{self.__class__.__name__} Forecast Results')\n",
    "        plt.legend()\n",
    "        plt.show()\n",
    "\n",
    "    def diagnostic_plots(self):\n",
    "        \"\"\"Generate model diagnostic plots if available\"\"\"\n",
    "        if self.model:\n",
    "            try:\n",
    "                return self.model.plot_diagnostics(figsize=(12, 8))\n",
    "            except AttributeError:\n",
    "                print(f\"{self.__class__.__name__} does not support diagnostic plots\")\n",
    "        else:\n",
    "            print(\"Model not trained - call fit_model() first\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "id": "88528dba",
   "metadata": {},
   "outputs": [],
   "source": [
    "class ARIMAModel(BaseTimeSeriesModel):\n",
    "    def __init__(self, *args, **kwargs):\n",
    "        super().__init__(*args, **kwargs)\n",
    "        self.best_order = None\n",
    "        self.d = 0\n",
    "\n",
    "    def check_stationarity(self, series: pd.Series) -> bool:\n",
    "        from statsmodels.tsa.stattools import adfuller\n",
    "        result = adfuller(series.dropna())\n",
    "        return result[1] <= 0.05\n",
    "    \n",
    "\n",
    "    def _auto_diff(self, series: pd.Series) -> int:\n",
    "        \"\"\"Determine optimal differencing using training data\"\"\"\n",
    "        from pmdarima.utils import ndiffs\n",
    "        self._d = ndiffs(series, test='adf')\n",
    "        return self._d\n",
    "\n",
    "    def preprocess_data(self):\n",
    "        current_series = self.series.copy()\n",
    "        self.d = 0\n",
    "        while not self.check_stationarity(current_series):\n",
    "            current_series = current_series.diff().dropna()\n",
    "            self.d += 1\n",
    "        self.series = current_series\n",
    "\n",
    "    def grid_search(self, pdq_range=(2, 1, 2)):\n",
    "        from statsmodels.tsa.arima.model import ARIMA\n",
    "        import numpy as np\n",
    "        best_aic = np.inf\n",
    "        p_range, d_range, q_range = pdq_range\n",
    "        for p in range(p_range + 1):\n",
    "            for d in range(d_range + 1):\n",
    "                for q in range(q_range + 1):\n",
    "                    try:\n",
    "                        model = ARIMA(self.train, order=(p, d, q)).fit()\n",
    "                        if model.aic < best_aic:\n",
    "                            best_aic = model.aic\n",
    "                            self.best_order = (p, d, q)\n",
    "                    except:\n",
    "                        continue\n",
    "        print(f\"Best ARIMA order: {self.best_order} (AIC: {best_aic})\")\n",
    "\n",
    "    # def grid_search(self, p_range=3, q_range=3):\n",
    "    #     \"\"\"Auto ARIMA implementation with proper differencing\"\"\"\n",
    "    #     from pmdarima import auto_arima\n",
    "    #     self._auto_diff(self.train)\n",
    "        \n",
    "    #     model = auto_arima(\n",
    "    #         self.train,\n",
    "    #         d=self._d,\n",
    "    #         max_p=p_range,\n",
    "    #         max_q=q_range,\n",
    "    #         seasonal=False,\n",
    "    #         trace=True\n",
    "    #     )\n",
    "    #     self.best_order = model.order\n",
    "\n",
    "    def fit_model(self, order=None):\n",
    "        from statsmodels.tsa.arima.model import ARIMA\n",
    "        if order is None:\n",
    "            order = self.best_order\n",
    "        self.model = ARIMA(self.train, order=order).fit()\n",
    "\n",
    "    # def forecast(self, steps: int):\n",
    "    #     return self.model.get_forecast(steps=steps).predicted_mean\n",
    "    \n",
    "    # def forecast(self, steps: int) -> Tuple[pd.Series, pd.Series, pd.Series]:\n",
    "    #     \"\"\"Returns (mean, lower, upper)\"\"\"\n",
    "    #     forecast = self.model.get_forecast(steps=steps)\n",
    "    #     return forecast.predicted_mean, forecast.conf_int().iloc[:,0], forecast.conf_int().iloc[:,1]\n",
    "    \n",
    "\n",
    "    def forecast(self, steps: int) -> pd.DataFrame:\n",
    "        \"\"\"\n",
    "        Returns a DataFrame with forecast, lower, and upper confidence intervals.\n",
    "        \"\"\"\n",
    "        forecast_res = self.model.get_forecast(steps=steps)\n",
    "        forecast_df = forecast_res.conf_int()\n",
    "        forecast_df['forecast'] = forecast_res.predicted_mean\n",
    "        forecast_df.rename(columns={forecast_df.columns[0]: 'lower', forecast_df.columns[1]: 'upper'}, inplace=True)\n",
    "        return forecast_df[['forecast', 'lower', 'upper']]\n",
    "\n",
    "\n",
    "    # def forecast(self, steps: int) -> pd.DataFrame:\n",
    "    #     \"\"\"Auto-inverse differencing for proper scaling\"\"\"\n",
    "    #     # Get differenced forecast\n",
    "    #     diff_forecast = self.model.get_forecast(steps=steps)\n",
    "        \n",
    "    #     # Reintegrate forecasts\n",
    "    #     last_value = self.full_series.iloc[-self._d-1] if self._d > 0 else None\n",
    "    #     forecast = self._inverse_diff(diff_forecast, last_value)\n",
    "        \n",
    "    #     return forecast\n",
    "    \n",
    "    def _inverse_diff(self, diff_forecast, last_obs=None):\n",
    "        \"\"\"Reverse differencing transformations\"\"\"\n",
    "        if self._d == 0:\n",
    "            return diff_forecast\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "id": "624b1ef0",
   "metadata": {},
   "outputs": [],
   "source": [
    "class ExpSmoothingModel(BaseTimeSeriesModel):\n",
    "    def fit_model(self, trend='add', seasonal=None, seasonal_periods=None):\n",
    "        from statsmodels.tsa.holtwinters import ExponentialSmoothing\n",
    "        self.model = ExponentialSmoothing(\n",
    "            self.train,\n",
    "            trend=trend,\n",
    "            seasonal=seasonal,\n",
    "            seasonal_periods=seasonal_periods\n",
    "        ).fit()\n",
    "\n",
    "    # def forecast(self, steps: int):\n",
    "    #     return self.model.forecast(steps)\n",
    "    def forecast(self, steps: int) -> pd.Series:\n",
    "        \"\"\"Returns only point forecasts\"\"\"\n",
    "        return self.model.forecast(steps)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "id": "9e1b0fb3",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "First 5 rows:\n",
      "           financial_year   month        state district  \\\n",
      "date                                                      \n",
      "2017-04-01      2017-2018   April  Maharashtra    THANE   \n",
      "2017-05-01      2017-2018     May  Maharashtra    THANE   \n",
      "2017-06-01      2017-2018    June  Maharashtra    THANE   \n",
      "2017-07-01      2017-2018    July  Maharashtra    THANE   \n",
      "2017-08-01      2017-2018  August  Maharashtra    THANE   \n",
      "\n",
      "                    indicator_type  fy_id  mnth_id  st_id  dt_id     I1  ...  \\\n",
      "date                                                                     ...   \n",
      "2017-04-01  Total [(A+B) or (C+D)]      1        2     22    437  14549  ...   \n",
      "2017-05-01  Total [(A+B) or (C+D)]      1        3     22    437  13790  ...   \n",
      "2017-06-01  Total [(A+B) or (C+D)]      1        4     22    437  14818  ...   \n",
      "2017-07-01  Total [(A+B) or (C+D)]      1        5     22    437  17290  ...   \n",
      "2017-08-01  Total [(A+B) or (C+D)]      1        6     22    437  14479  ...   \n",
      "\n",
      "            I277  I278  I279  I280  I281  I282  I283  I284  I285  I286  \n",
      "date                                                                    \n",
      "2017-04-01     1    44    19    55     0     0     0     0     0     0  \n",
      "2017-05-01     2    32    17    53     0     0     0     0     0     0  \n",
      "2017-06-01     4    54    34    61     0     0     0     0     0     0  \n",
      "2017-07-01     5    54    42   101     0     0     0     0     0     0  \n",
      "2017-08-01     2    50    45    99     0     0     0     0     0     0  \n",
      "\n",
      "[5 rows x 295 columns]\n",
      "\n",
      "Data shape: (48,)\n",
      "\n",
      "Missing values:\n",
      "financial_year    0\n",
      "month             0\n",
      "state             0\n",
      "district          0\n",
      "indicator_type    0\n",
      "                 ..\n",
      "I282              0\n",
      "I283              0\n",
      "I284              0\n",
      "I285              0\n",
      "I286              0\n",
      "Length: 295, dtype: int64\n",
      "\n",
      "Data types:\n",
      "financial_year    object\n",
      "month             object\n",
      "state             object\n",
      "district          object\n",
      "indicator_type    object\n",
      "                   ...  \n",
      "I282               int64\n",
      "I283               int64\n",
      "I284               int64\n",
      "I285               int64\n",
      "I286               int64\n",
      "Length: 295, dtype: object\n",
      "\n",
      "Selected value column: I1\n",
      "Train Data:\n",
      "date\n",
      "2017-04-01    14549\n",
      "2017-05-01    13790\n",
      "2017-06-01    14818\n",
      "2017-07-01    17290\n",
      "2017-08-01    14479\n",
      "Freq: MS, Name: I1, dtype: int64\n",
      "Train shape: (38,)\n",
      "\n",
      "Test Data:\n",
      "date\n",
      "2020-06-01    13519\n",
      "2020-07-01    12050\n",
      "2020-08-01    12215\n",
      "2020-09-01    13770\n",
      "2020-10-01    13402\n",
      "Freq: MS, Name: I1, dtype: int64\n",
      "Test shape: (10,)\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\Users\\nauti\\AppData\\Local\\Programs\\Python\\Python311\\Lib\\site-packages\\statsmodels\\tsa\\statespace\\sarimax.py:966: UserWarning: Non-stationary starting autoregressive parameters found. Using zeros as starting parameters.\n",
      "  warn('Non-stationary starting autoregressive parameters'\n",
      "c:\\Users\\nauti\\AppData\\Local\\Programs\\Python\\Python311\\Lib\\site-packages\\statsmodels\\tsa\\statespace\\sarimax.py:978: UserWarning: Non-invertible starting MA parameters found. Using zeros as starting parameters.\n",
      "  warn('Non-invertible starting MA parameters found.'\n",
      "c:\\Users\\nauti\\AppData\\Local\\Programs\\Python\\Python311\\Lib\\site-packages\\statsmodels\\tsa\\statespace\\sarimax.py:978: UserWarning: Non-invertible starting MA parameters found. Using zeros as starting parameters.\n",
      "  warn('Non-invertible starting MA parameters found.'\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Best ARIMA order: (1, 1, 0) (AIC: 625.2459412757274)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\Users\\nauti\\AppData\\Local\\Programs\\Python\\Python311\\Lib\\site-packages\\sklearn\\metrics\\_regression.py:483: FutureWarning: 'squared' is deprecated in version 1.4 and will be removed in 1.6. To calculate the root mean squared error, use the function'root_mean_squared_error'.\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "ename": "ValueError",
     "evalue": "y_true and y_pred have different number of output (1!=3)",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mValueError\u001b[0m                                Traceback (most recent call last)",
      "Cell \u001b[1;32mIn[43], line 18\u001b[0m\n\u001b[0;32m     16\u001b[0m arima\u001b[38;5;241m.\u001b[39mfit_model()\n\u001b[0;32m     17\u001b[0m arima_forecast \u001b[38;5;241m=\u001b[39m arima\u001b[38;5;241m.\u001b[39mforecast(\u001b[38;5;28mlen\u001b[39m(arima\u001b[38;5;241m.\u001b[39mtest))\n\u001b[1;32m---> 18\u001b[0m arima_rmse \u001b[38;5;241m=\u001b[39m \u001b[43marima\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mevaluate\u001b[49m\u001b[43m(\u001b[49m\u001b[43marima_forecast\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m     19\u001b[0m \u001b[38;5;28mprint\u001b[39m(\u001b[38;5;124mf\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mARIMA RMSE: \u001b[39m\u001b[38;5;132;01m{\u001b[39;00marima_rmse\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m\"\u001b[39m)\n",
      "Cell \u001b[1;32mIn[29], line 64\u001b[0m, in \u001b[0;36mBaseTimeSeriesModel.evaluate\u001b[1;34m(self, forecast)\u001b[0m\n\u001b[0;32m     60\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21mevaluate\u001b[39m(\u001b[38;5;28mself\u001b[39m, forecast: pd\u001b[38;5;241m.\u001b[39mSeries):\n\u001b[0;32m     61\u001b[0m     \u001b[38;5;28;01mfrom\u001b[39;00m \u001b[38;5;21;01msklearn\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mmetrics\u001b[39;00m \u001b[38;5;28;01mimport\u001b[39;00m mean_absolute_error, mean_absolute_percentage_error\n\u001b[0;32m     63\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m {\n\u001b[1;32m---> 64\u001b[0m         \u001b[38;5;124m'\u001b[39m\u001b[38;5;124mRMSE\u001b[39m\u001b[38;5;124m'\u001b[39m: \u001b[43mmean_squared_error\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mtest\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mforecast\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43msquared\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;28;43;01mFalse\u001b[39;49;00m\u001b[43m)\u001b[49m,\n\u001b[0;32m     65\u001b[0m         \u001b[38;5;124m'\u001b[39m\u001b[38;5;124mMAE\u001b[39m\u001b[38;5;124m'\u001b[39m: mean_absolute_error(\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mtest, forecast),\n\u001b[0;32m     66\u001b[0m         \u001b[38;5;124m'\u001b[39m\u001b[38;5;124mMAPE\u001b[39m\u001b[38;5;124m'\u001b[39m: mean_absolute_percentage_error(\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mtest, forecast)\n\u001b[0;32m     67\u001b[0m     }\n",
      "File \u001b[1;32mc:\\Users\\nauti\\AppData\\Local\\Programs\\Python\\Python311\\Lib\\site-packages\\sklearn\\utils\\_param_validation.py:213\u001b[0m, in \u001b[0;36mvalidate_params.<locals>.decorator.<locals>.wrapper\u001b[1;34m(*args, **kwargs)\u001b[0m\n\u001b[0;32m    207\u001b[0m \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[0;32m    208\u001b[0m     \u001b[38;5;28;01mwith\u001b[39;00m config_context(\n\u001b[0;32m    209\u001b[0m         skip_parameter_validation\u001b[38;5;241m=\u001b[39m(\n\u001b[0;32m    210\u001b[0m             prefer_skip_nested_validation \u001b[38;5;129;01mor\u001b[39;00m global_skip_validation\n\u001b[0;32m    211\u001b[0m         )\n\u001b[0;32m    212\u001b[0m     ):\n\u001b[1;32m--> 213\u001b[0m         \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mfunc\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m    214\u001b[0m \u001b[38;5;28;01mexcept\u001b[39;00m InvalidParameterError \u001b[38;5;28;01mas\u001b[39;00m e:\n\u001b[0;32m    215\u001b[0m     \u001b[38;5;66;03m# When the function is just a wrapper around an estimator, we allow\u001b[39;00m\n\u001b[0;32m    216\u001b[0m     \u001b[38;5;66;03m# the function to delegate validation to the estimator, but we replace\u001b[39;00m\n\u001b[0;32m    217\u001b[0m     \u001b[38;5;66;03m# the name of the estimator by the name of the function in the error\u001b[39;00m\n\u001b[0;32m    218\u001b[0m     \u001b[38;5;66;03m# message to avoid confusion.\u001b[39;00m\n\u001b[0;32m    219\u001b[0m     msg \u001b[38;5;241m=\u001b[39m re\u001b[38;5;241m.\u001b[39msub(\n\u001b[0;32m    220\u001b[0m         \u001b[38;5;124mr\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mparameter of \u001b[39m\u001b[38;5;124m\\\u001b[39m\u001b[38;5;124mw+ must be\u001b[39m\u001b[38;5;124m\"\u001b[39m,\n\u001b[0;32m    221\u001b[0m         \u001b[38;5;124mf\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mparameter of \u001b[39m\u001b[38;5;132;01m{\u001b[39;00mfunc\u001b[38;5;241m.\u001b[39m\u001b[38;5;18m__qualname__\u001b[39m\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m must be\u001b[39m\u001b[38;5;124m\"\u001b[39m,\n\u001b[0;32m    222\u001b[0m         \u001b[38;5;28mstr\u001b[39m(e),\n\u001b[0;32m    223\u001b[0m     )\n",
      "File \u001b[1;32mc:\\Users\\nauti\\AppData\\Local\\Programs\\Python\\Python311\\Lib\\site-packages\\sklearn\\metrics\\_regression.py:493\u001b[0m, in \u001b[0;36mmean_squared_error\u001b[1;34m(y_true, y_pred, sample_weight, multioutput, squared)\u001b[0m\n\u001b[0;32m    483\u001b[0m     warnings\u001b[38;5;241m.\u001b[39mwarn(\n\u001b[0;32m    484\u001b[0m         (\n\u001b[0;32m    485\u001b[0m             \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124m'\u001b[39m\u001b[38;5;124msquared\u001b[39m\u001b[38;5;124m'\u001b[39m\u001b[38;5;124m is deprecated in version 1.4 and \u001b[39m\u001b[38;5;124m\"\u001b[39m\n\u001b[1;32m   (...)\u001b[0m\n\u001b[0;32m    490\u001b[0m         \u001b[38;5;167;01mFutureWarning\u001b[39;00m,\n\u001b[0;32m    491\u001b[0m     )\n\u001b[0;32m    492\u001b[0m     \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m squared:\n\u001b[1;32m--> 493\u001b[0m         \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mroot_mean_squared_error\u001b[49m\u001b[43m(\u001b[49m\n\u001b[0;32m    494\u001b[0m \u001b[43m            \u001b[49m\u001b[43my_true\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43my_pred\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43msample_weight\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43msample_weight\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mmultioutput\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mmultioutput\u001b[49m\n\u001b[0;32m    495\u001b[0m \u001b[43m        \u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m    497\u001b[0m y_type, y_true, y_pred, multioutput \u001b[38;5;241m=\u001b[39m _check_reg_targets(\n\u001b[0;32m    498\u001b[0m     y_true, y_pred, multioutput\n\u001b[0;32m    499\u001b[0m )\n\u001b[0;32m    500\u001b[0m check_consistent_length(y_true, y_pred, sample_weight)\n",
      "File \u001b[1;32mc:\\Users\\nauti\\AppData\\Local\\Programs\\Python\\Python311\\Lib\\site-packages\\sklearn\\utils\\_param_validation.py:186\u001b[0m, in \u001b[0;36mvalidate_params.<locals>.decorator.<locals>.wrapper\u001b[1;34m(*args, **kwargs)\u001b[0m\n\u001b[0;32m    184\u001b[0m global_skip_validation \u001b[38;5;241m=\u001b[39m get_config()[\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mskip_parameter_validation\u001b[39m\u001b[38;5;124m\"\u001b[39m]\n\u001b[0;32m    185\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m global_skip_validation:\n\u001b[1;32m--> 186\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mfunc\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m    188\u001b[0m func_sig \u001b[38;5;241m=\u001b[39m signature(func)\n\u001b[0;32m    190\u001b[0m \u001b[38;5;66;03m# Map *args/**kwargs to the function signature\u001b[39;00m\n",
      "File \u001b[1;32mc:\\Users\\nauti\\AppData\\Local\\Programs\\Python\\Python311\\Lib\\site-packages\\sklearn\\metrics\\_regression.py:572\u001b[0m, in \u001b[0;36mroot_mean_squared_error\u001b[1;34m(y_true, y_pred, sample_weight, multioutput)\u001b[0m\n\u001b[0;32m    513\u001b[0m \u001b[38;5;129m@validate_params\u001b[39m(\n\u001b[0;32m    514\u001b[0m     {\n\u001b[0;32m    515\u001b[0m         \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124my_true\u001b[39m\u001b[38;5;124m\"\u001b[39m: [\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124marray-like\u001b[39m\u001b[38;5;124m\"\u001b[39m],\n\u001b[1;32m   (...)\u001b[0m\n\u001b[0;32m    523\u001b[0m     y_true, y_pred, \u001b[38;5;241m*\u001b[39m, sample_weight\u001b[38;5;241m=\u001b[39m\u001b[38;5;28;01mNone\u001b[39;00m, multioutput\u001b[38;5;241m=\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124muniform_average\u001b[39m\u001b[38;5;124m\"\u001b[39m\n\u001b[0;32m    524\u001b[0m ):\n\u001b[0;32m    525\u001b[0m \u001b[38;5;250m    \u001b[39m\u001b[38;5;124;03m\"\"\"Root mean squared error regression loss.\u001b[39;00m\n\u001b[0;32m    526\u001b[0m \n\u001b[0;32m    527\u001b[0m \u001b[38;5;124;03m    Read more in the :ref:`User Guide <mean_squared_error>`.\u001b[39;00m\n\u001b[1;32m   (...)\u001b[0m\n\u001b[0;32m    569\u001b[0m \u001b[38;5;124;03m    0.822...\u001b[39;00m\n\u001b[0;32m    570\u001b[0m \u001b[38;5;124;03m    \"\"\"\u001b[39;00m\n\u001b[0;32m    571\u001b[0m     output_errors \u001b[38;5;241m=\u001b[39m np\u001b[38;5;241m.\u001b[39msqrt(\n\u001b[1;32m--> 572\u001b[0m         \u001b[43mmean_squared_error\u001b[49m\u001b[43m(\u001b[49m\n\u001b[0;32m    573\u001b[0m \u001b[43m            \u001b[49m\u001b[43my_true\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43my_pred\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43msample_weight\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43msample_weight\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mmultioutput\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[38;5;124;43mraw_values\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\n\u001b[0;32m    574\u001b[0m \u001b[43m        \u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m    575\u001b[0m     )\n\u001b[0;32m    577\u001b[0m     \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28misinstance\u001b[39m(multioutput, \u001b[38;5;28mstr\u001b[39m):\n\u001b[0;32m    578\u001b[0m         \u001b[38;5;28;01mif\u001b[39;00m multioutput \u001b[38;5;241m==\u001b[39m \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mraw_values\u001b[39m\u001b[38;5;124m\"\u001b[39m:\n",
      "File \u001b[1;32mc:\\Users\\nauti\\AppData\\Local\\Programs\\Python\\Python311\\Lib\\site-packages\\sklearn\\utils\\_param_validation.py:186\u001b[0m, in \u001b[0;36mvalidate_params.<locals>.decorator.<locals>.wrapper\u001b[1;34m(*args, **kwargs)\u001b[0m\n\u001b[0;32m    184\u001b[0m global_skip_validation \u001b[38;5;241m=\u001b[39m get_config()[\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mskip_parameter_validation\u001b[39m\u001b[38;5;124m\"\u001b[39m]\n\u001b[0;32m    185\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m global_skip_validation:\n\u001b[1;32m--> 186\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mfunc\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m    188\u001b[0m func_sig \u001b[38;5;241m=\u001b[39m signature(func)\n\u001b[0;32m    190\u001b[0m \u001b[38;5;66;03m# Map *args/**kwargs to the function signature\u001b[39;00m\n",
      "File \u001b[1;32mc:\\Users\\nauti\\AppData\\Local\\Programs\\Python\\Python311\\Lib\\site-packages\\sklearn\\metrics\\_regression.py:497\u001b[0m, in \u001b[0;36mmean_squared_error\u001b[1;34m(y_true, y_pred, sample_weight, multioutput, squared)\u001b[0m\n\u001b[0;32m    492\u001b[0m     \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m squared:\n\u001b[0;32m    493\u001b[0m         \u001b[38;5;28;01mreturn\u001b[39;00m root_mean_squared_error(\n\u001b[0;32m    494\u001b[0m             y_true, y_pred, sample_weight\u001b[38;5;241m=\u001b[39msample_weight, multioutput\u001b[38;5;241m=\u001b[39mmultioutput\n\u001b[0;32m    495\u001b[0m         )\n\u001b[1;32m--> 497\u001b[0m y_type, y_true, y_pred, multioutput \u001b[38;5;241m=\u001b[39m \u001b[43m_check_reg_targets\u001b[49m\u001b[43m(\u001b[49m\n\u001b[0;32m    498\u001b[0m \u001b[43m    \u001b[49m\u001b[43my_true\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43my_pred\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mmultioutput\u001b[49m\n\u001b[0;32m    499\u001b[0m \u001b[43m\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m    500\u001b[0m check_consistent_length(y_true, y_pred, sample_weight)\n\u001b[0;32m    501\u001b[0m output_errors \u001b[38;5;241m=\u001b[39m np\u001b[38;5;241m.\u001b[39maverage((y_true \u001b[38;5;241m-\u001b[39m y_pred) \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39m \u001b[38;5;241m2\u001b[39m, axis\u001b[38;5;241m=\u001b[39m\u001b[38;5;241m0\u001b[39m, weights\u001b[38;5;241m=\u001b[39msample_weight)\n",
      "File \u001b[1;32mc:\\Users\\nauti\\AppData\\Local\\Programs\\Python\\Python311\\Lib\\site-packages\\sklearn\\metrics\\_regression.py:113\u001b[0m, in \u001b[0;36m_check_reg_targets\u001b[1;34m(y_true, y_pred, multioutput, dtype)\u001b[0m\n\u001b[0;32m    110\u001b[0m     y_pred \u001b[38;5;241m=\u001b[39m y_pred\u001b[38;5;241m.\u001b[39mreshape((\u001b[38;5;241m-\u001b[39m\u001b[38;5;241m1\u001b[39m, \u001b[38;5;241m1\u001b[39m))\n\u001b[0;32m    112\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m y_true\u001b[38;5;241m.\u001b[39mshape[\u001b[38;5;241m1\u001b[39m] \u001b[38;5;241m!=\u001b[39m y_pred\u001b[38;5;241m.\u001b[39mshape[\u001b[38;5;241m1\u001b[39m]:\n\u001b[1;32m--> 113\u001b[0m     \u001b[38;5;28;01mraise\u001b[39;00m \u001b[38;5;167;01mValueError\u001b[39;00m(\n\u001b[0;32m    114\u001b[0m         \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124my_true and y_pred have different number of output (\u001b[39m\u001b[38;5;132;01m{0}\u001b[39;00m\u001b[38;5;124m!=\u001b[39m\u001b[38;5;132;01m{1}\u001b[39;00m\u001b[38;5;124m)\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;241m.\u001b[39mformat(\n\u001b[0;32m    115\u001b[0m             y_true\u001b[38;5;241m.\u001b[39mshape[\u001b[38;5;241m1\u001b[39m], y_pred\u001b[38;5;241m.\u001b[39mshape[\u001b[38;5;241m1\u001b[39m]\n\u001b[0;32m    116\u001b[0m         )\n\u001b[0;32m    117\u001b[0m     )\n\u001b[0;32m    119\u001b[0m n_outputs \u001b[38;5;241m=\u001b[39m y_true\u001b[38;5;241m.\u001b[39mshape[\u001b[38;5;241m1\u001b[39m]\n\u001b[0;32m    120\u001b[0m allowed_multioutput_str \u001b[38;5;241m=\u001b[39m (\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mraw_values\u001b[39m\u001b[38;5;124m\"\u001b[39m, \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124muniform_average\u001b[39m\u001b[38;5;124m\"\u001b[39m, \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mvariance_weighted\u001b[39m\u001b[38;5;124m\"\u001b[39m)\n",
      "\u001b[1;31mValueError\u001b[0m: y_true and y_pred have different number of output (1!=3)"
     ]
    }
   ],
   "source": [
    "# ARIMA Example\n",
    "arima = ARIMAModel(   \n",
    "    file_path=\"../data/HMIS_DATA_CORRECTED_17_21/mh_dist17_21_with_IDs_date_correction.csv\",\n",
    "    value_col=\"I1\",\n",
    "    selected_district=\"THANE\",\n",
    "    test_size=0.2\n",
    ")\n",
    "\n",
    "\n",
    "\n",
    "arima.print_df()\n",
    "arima.preprocess_data()\n",
    "arima.split_data()\n",
    "arima.print_train_test()\n",
    "arima.grid_search(pdq_range=(2, 1, 2))\n",
    "arima.fit_model()\n",
    "arima_forecast = arima.forecast(len(arima.test))\n",
    "arima_rmse = arima.evaluate(arima_forecast)\n",
    "print(f\"ARIMA RMSE: {arima_rmse}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "id": "11fbd137",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\Users\\nauti\\AppData\\Local\\Programs\\Python\\Python311\\Lib\\site-packages\\statsmodels\\tsa\\statespace\\sarimax.py:966: UserWarning: Non-stationary starting autoregressive parameters found. Using zeros as starting parameters.\n",
      "  warn('Non-stationary starting autoregressive parameters'\n",
      "c:\\Users\\nauti\\AppData\\Local\\Programs\\Python\\Python311\\Lib\\site-packages\\statsmodels\\tsa\\statespace\\sarimax.py:978: UserWarning: Non-invertible starting MA parameters found. Using zeros as starting parameters.\n",
      "  warn('Non-invertible starting MA parameters found.'\n",
      "c:\\Users\\nauti\\AppData\\Local\\Programs\\Python\\Python311\\Lib\\site-packages\\statsmodels\\tsa\\statespace\\sarimax.py:978: UserWarning: Non-invertible starting MA parameters found. Using zeros as starting parameters.\n",
      "  warn('Non-invertible starting MA parameters found.'\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Best ARIMA order: (1, 1, 0) (AIC: 625.2459412757274)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\Users\\nauti\\AppData\\Local\\Programs\\Python\\Python311\\Lib\\site-packages\\sklearn\\metrics\\_regression.py:483: FutureWarning: 'squared' is deprecated in version 1.4 and will be removed in 1.6. To calculate the root mean squared error, use the function'root_mean_squared_error'.\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "ename": "ValueError",
     "evalue": "y_true and y_pred have different number of output (1!=3)",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mValueError\u001b[0m                                Traceback (most recent call last)",
      "Cell \u001b[1;32mIn[44], line 11\u001b[0m\n\u001b[0;32m      9\u001b[0m model\u001b[38;5;241m.\u001b[39mfit_model()\n\u001b[0;32m     10\u001b[0m forecast \u001b[38;5;241m=\u001b[39m model\u001b[38;5;241m.\u001b[39mforecast(steps\u001b[38;5;241m=\u001b[39m\u001b[38;5;28mlen\u001b[39m(model\u001b[38;5;241m.\u001b[39mtest))\n\u001b[1;32m---> 11\u001b[0m \u001b[38;5;28mprint\u001b[39m(\u001b[43mmodel\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mevaluate\u001b[49m\u001b[43m(\u001b[49m\u001b[43mforecast\u001b[49m\u001b[43m)\u001b[49m)\n\u001b[0;32m     12\u001b[0m model\u001b[38;5;241m.\u001b[39mplot_results(forecast)\n",
      "Cell \u001b[1;32mIn[29], line 64\u001b[0m, in \u001b[0;36mBaseTimeSeriesModel.evaluate\u001b[1;34m(self, forecast)\u001b[0m\n\u001b[0;32m     60\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21mevaluate\u001b[39m(\u001b[38;5;28mself\u001b[39m, forecast: pd\u001b[38;5;241m.\u001b[39mSeries):\n\u001b[0;32m     61\u001b[0m     \u001b[38;5;28;01mfrom\u001b[39;00m \u001b[38;5;21;01msklearn\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mmetrics\u001b[39;00m \u001b[38;5;28;01mimport\u001b[39;00m mean_absolute_error, mean_absolute_percentage_error\n\u001b[0;32m     63\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m {\n\u001b[1;32m---> 64\u001b[0m         \u001b[38;5;124m'\u001b[39m\u001b[38;5;124mRMSE\u001b[39m\u001b[38;5;124m'\u001b[39m: \u001b[43mmean_squared_error\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mtest\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mforecast\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43msquared\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;28;43;01mFalse\u001b[39;49;00m\u001b[43m)\u001b[49m,\n\u001b[0;32m     65\u001b[0m         \u001b[38;5;124m'\u001b[39m\u001b[38;5;124mMAE\u001b[39m\u001b[38;5;124m'\u001b[39m: mean_absolute_error(\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mtest, forecast),\n\u001b[0;32m     66\u001b[0m         \u001b[38;5;124m'\u001b[39m\u001b[38;5;124mMAPE\u001b[39m\u001b[38;5;124m'\u001b[39m: mean_absolute_percentage_error(\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mtest, forecast)\n\u001b[0;32m     67\u001b[0m     }\n",
      "File \u001b[1;32mc:\\Users\\nauti\\AppData\\Local\\Programs\\Python\\Python311\\Lib\\site-packages\\sklearn\\utils\\_param_validation.py:213\u001b[0m, in \u001b[0;36mvalidate_params.<locals>.decorator.<locals>.wrapper\u001b[1;34m(*args, **kwargs)\u001b[0m\n\u001b[0;32m    207\u001b[0m \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[0;32m    208\u001b[0m     \u001b[38;5;28;01mwith\u001b[39;00m config_context(\n\u001b[0;32m    209\u001b[0m         skip_parameter_validation\u001b[38;5;241m=\u001b[39m(\n\u001b[0;32m    210\u001b[0m             prefer_skip_nested_validation \u001b[38;5;129;01mor\u001b[39;00m global_skip_validation\n\u001b[0;32m    211\u001b[0m         )\n\u001b[0;32m    212\u001b[0m     ):\n\u001b[1;32m--> 213\u001b[0m         \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mfunc\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m    214\u001b[0m \u001b[38;5;28;01mexcept\u001b[39;00m InvalidParameterError \u001b[38;5;28;01mas\u001b[39;00m e:\n\u001b[0;32m    215\u001b[0m     \u001b[38;5;66;03m# When the function is just a wrapper around an estimator, we allow\u001b[39;00m\n\u001b[0;32m    216\u001b[0m     \u001b[38;5;66;03m# the function to delegate validation to the estimator, but we replace\u001b[39;00m\n\u001b[0;32m    217\u001b[0m     \u001b[38;5;66;03m# the name of the estimator by the name of the function in the error\u001b[39;00m\n\u001b[0;32m    218\u001b[0m     \u001b[38;5;66;03m# message to avoid confusion.\u001b[39;00m\n\u001b[0;32m    219\u001b[0m     msg \u001b[38;5;241m=\u001b[39m re\u001b[38;5;241m.\u001b[39msub(\n\u001b[0;32m    220\u001b[0m         \u001b[38;5;124mr\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mparameter of \u001b[39m\u001b[38;5;124m\\\u001b[39m\u001b[38;5;124mw+ must be\u001b[39m\u001b[38;5;124m\"\u001b[39m,\n\u001b[0;32m    221\u001b[0m         \u001b[38;5;124mf\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mparameter of \u001b[39m\u001b[38;5;132;01m{\u001b[39;00mfunc\u001b[38;5;241m.\u001b[39m\u001b[38;5;18m__qualname__\u001b[39m\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m must be\u001b[39m\u001b[38;5;124m\"\u001b[39m,\n\u001b[0;32m    222\u001b[0m         \u001b[38;5;28mstr\u001b[39m(e),\n\u001b[0;32m    223\u001b[0m     )\n",
      "File \u001b[1;32mc:\\Users\\nauti\\AppData\\Local\\Programs\\Python\\Python311\\Lib\\site-packages\\sklearn\\metrics\\_regression.py:493\u001b[0m, in \u001b[0;36mmean_squared_error\u001b[1;34m(y_true, y_pred, sample_weight, multioutput, squared)\u001b[0m\n\u001b[0;32m    483\u001b[0m     warnings\u001b[38;5;241m.\u001b[39mwarn(\n\u001b[0;32m    484\u001b[0m         (\n\u001b[0;32m    485\u001b[0m             \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124m'\u001b[39m\u001b[38;5;124msquared\u001b[39m\u001b[38;5;124m'\u001b[39m\u001b[38;5;124m is deprecated in version 1.4 and \u001b[39m\u001b[38;5;124m\"\u001b[39m\n\u001b[1;32m   (...)\u001b[0m\n\u001b[0;32m    490\u001b[0m         \u001b[38;5;167;01mFutureWarning\u001b[39;00m,\n\u001b[0;32m    491\u001b[0m     )\n\u001b[0;32m    492\u001b[0m     \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m squared:\n\u001b[1;32m--> 493\u001b[0m         \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mroot_mean_squared_error\u001b[49m\u001b[43m(\u001b[49m\n\u001b[0;32m    494\u001b[0m \u001b[43m            \u001b[49m\u001b[43my_true\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43my_pred\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43msample_weight\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43msample_weight\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mmultioutput\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mmultioutput\u001b[49m\n\u001b[0;32m    495\u001b[0m \u001b[43m        \u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m    497\u001b[0m y_type, y_true, y_pred, multioutput \u001b[38;5;241m=\u001b[39m _check_reg_targets(\n\u001b[0;32m    498\u001b[0m     y_true, y_pred, multioutput\n\u001b[0;32m    499\u001b[0m )\n\u001b[0;32m    500\u001b[0m check_consistent_length(y_true, y_pred, sample_weight)\n",
      "File \u001b[1;32mc:\\Users\\nauti\\AppData\\Local\\Programs\\Python\\Python311\\Lib\\site-packages\\sklearn\\utils\\_param_validation.py:186\u001b[0m, in \u001b[0;36mvalidate_params.<locals>.decorator.<locals>.wrapper\u001b[1;34m(*args, **kwargs)\u001b[0m\n\u001b[0;32m    184\u001b[0m global_skip_validation \u001b[38;5;241m=\u001b[39m get_config()[\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mskip_parameter_validation\u001b[39m\u001b[38;5;124m\"\u001b[39m]\n\u001b[0;32m    185\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m global_skip_validation:\n\u001b[1;32m--> 186\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mfunc\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m    188\u001b[0m func_sig \u001b[38;5;241m=\u001b[39m signature(func)\n\u001b[0;32m    190\u001b[0m \u001b[38;5;66;03m# Map *args/**kwargs to the function signature\u001b[39;00m\n",
      "File \u001b[1;32mc:\\Users\\nauti\\AppData\\Local\\Programs\\Python\\Python311\\Lib\\site-packages\\sklearn\\metrics\\_regression.py:572\u001b[0m, in \u001b[0;36mroot_mean_squared_error\u001b[1;34m(y_true, y_pred, sample_weight, multioutput)\u001b[0m\n\u001b[0;32m    513\u001b[0m \u001b[38;5;129m@validate_params\u001b[39m(\n\u001b[0;32m    514\u001b[0m     {\n\u001b[0;32m    515\u001b[0m         \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124my_true\u001b[39m\u001b[38;5;124m\"\u001b[39m: [\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124marray-like\u001b[39m\u001b[38;5;124m\"\u001b[39m],\n\u001b[1;32m   (...)\u001b[0m\n\u001b[0;32m    523\u001b[0m     y_true, y_pred, \u001b[38;5;241m*\u001b[39m, sample_weight\u001b[38;5;241m=\u001b[39m\u001b[38;5;28;01mNone\u001b[39;00m, multioutput\u001b[38;5;241m=\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124muniform_average\u001b[39m\u001b[38;5;124m\"\u001b[39m\n\u001b[0;32m    524\u001b[0m ):\n\u001b[0;32m    525\u001b[0m \u001b[38;5;250m    \u001b[39m\u001b[38;5;124;03m\"\"\"Root mean squared error regression loss.\u001b[39;00m\n\u001b[0;32m    526\u001b[0m \n\u001b[0;32m    527\u001b[0m \u001b[38;5;124;03m    Read more in the :ref:`User Guide <mean_squared_error>`.\u001b[39;00m\n\u001b[1;32m   (...)\u001b[0m\n\u001b[0;32m    569\u001b[0m \u001b[38;5;124;03m    0.822...\u001b[39;00m\n\u001b[0;32m    570\u001b[0m \u001b[38;5;124;03m    \"\"\"\u001b[39;00m\n\u001b[0;32m    571\u001b[0m     output_errors \u001b[38;5;241m=\u001b[39m np\u001b[38;5;241m.\u001b[39msqrt(\n\u001b[1;32m--> 572\u001b[0m         \u001b[43mmean_squared_error\u001b[49m\u001b[43m(\u001b[49m\n\u001b[0;32m    573\u001b[0m \u001b[43m            \u001b[49m\u001b[43my_true\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43my_pred\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43msample_weight\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43msample_weight\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mmultioutput\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[38;5;124;43mraw_values\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\n\u001b[0;32m    574\u001b[0m \u001b[43m        \u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m    575\u001b[0m     )\n\u001b[0;32m    577\u001b[0m     \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28misinstance\u001b[39m(multioutput, \u001b[38;5;28mstr\u001b[39m):\n\u001b[0;32m    578\u001b[0m         \u001b[38;5;28;01mif\u001b[39;00m multioutput \u001b[38;5;241m==\u001b[39m \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mraw_values\u001b[39m\u001b[38;5;124m\"\u001b[39m:\n",
      "File \u001b[1;32mc:\\Users\\nauti\\AppData\\Local\\Programs\\Python\\Python311\\Lib\\site-packages\\sklearn\\utils\\_param_validation.py:186\u001b[0m, in \u001b[0;36mvalidate_params.<locals>.decorator.<locals>.wrapper\u001b[1;34m(*args, **kwargs)\u001b[0m\n\u001b[0;32m    184\u001b[0m global_skip_validation \u001b[38;5;241m=\u001b[39m get_config()[\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mskip_parameter_validation\u001b[39m\u001b[38;5;124m\"\u001b[39m]\n\u001b[0;32m    185\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m global_skip_validation:\n\u001b[1;32m--> 186\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mfunc\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m    188\u001b[0m func_sig \u001b[38;5;241m=\u001b[39m signature(func)\n\u001b[0;32m    190\u001b[0m \u001b[38;5;66;03m# Map *args/**kwargs to the function signature\u001b[39;00m\n",
      "File \u001b[1;32mc:\\Users\\nauti\\AppData\\Local\\Programs\\Python\\Python311\\Lib\\site-packages\\sklearn\\metrics\\_regression.py:497\u001b[0m, in \u001b[0;36mmean_squared_error\u001b[1;34m(y_true, y_pred, sample_weight, multioutput, squared)\u001b[0m\n\u001b[0;32m    492\u001b[0m     \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m squared:\n\u001b[0;32m    493\u001b[0m         \u001b[38;5;28;01mreturn\u001b[39;00m root_mean_squared_error(\n\u001b[0;32m    494\u001b[0m             y_true, y_pred, sample_weight\u001b[38;5;241m=\u001b[39msample_weight, multioutput\u001b[38;5;241m=\u001b[39mmultioutput\n\u001b[0;32m    495\u001b[0m         )\n\u001b[1;32m--> 497\u001b[0m y_type, y_true, y_pred, multioutput \u001b[38;5;241m=\u001b[39m \u001b[43m_check_reg_targets\u001b[49m\u001b[43m(\u001b[49m\n\u001b[0;32m    498\u001b[0m \u001b[43m    \u001b[49m\u001b[43my_true\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43my_pred\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mmultioutput\u001b[49m\n\u001b[0;32m    499\u001b[0m \u001b[43m\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m    500\u001b[0m check_consistent_length(y_true, y_pred, sample_weight)\n\u001b[0;32m    501\u001b[0m output_errors \u001b[38;5;241m=\u001b[39m np\u001b[38;5;241m.\u001b[39maverage((y_true \u001b[38;5;241m-\u001b[39m y_pred) \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39m \u001b[38;5;241m2\u001b[39m, axis\u001b[38;5;241m=\u001b[39m\u001b[38;5;241m0\u001b[39m, weights\u001b[38;5;241m=\u001b[39msample_weight)\n",
      "File \u001b[1;32mc:\\Users\\nauti\\AppData\\Local\\Programs\\Python\\Python311\\Lib\\site-packages\\sklearn\\metrics\\_regression.py:113\u001b[0m, in \u001b[0;36m_check_reg_targets\u001b[1;34m(y_true, y_pred, multioutput, dtype)\u001b[0m\n\u001b[0;32m    110\u001b[0m     y_pred \u001b[38;5;241m=\u001b[39m y_pred\u001b[38;5;241m.\u001b[39mreshape((\u001b[38;5;241m-\u001b[39m\u001b[38;5;241m1\u001b[39m, \u001b[38;5;241m1\u001b[39m))\n\u001b[0;32m    112\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m y_true\u001b[38;5;241m.\u001b[39mshape[\u001b[38;5;241m1\u001b[39m] \u001b[38;5;241m!=\u001b[39m y_pred\u001b[38;5;241m.\u001b[39mshape[\u001b[38;5;241m1\u001b[39m]:\n\u001b[1;32m--> 113\u001b[0m     \u001b[38;5;28;01mraise\u001b[39;00m \u001b[38;5;167;01mValueError\u001b[39;00m(\n\u001b[0;32m    114\u001b[0m         \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124my_true and y_pred have different number of output (\u001b[39m\u001b[38;5;132;01m{0}\u001b[39;00m\u001b[38;5;124m!=\u001b[39m\u001b[38;5;132;01m{1}\u001b[39;00m\u001b[38;5;124m)\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;241m.\u001b[39mformat(\n\u001b[0;32m    115\u001b[0m             y_true\u001b[38;5;241m.\u001b[39mshape[\u001b[38;5;241m1\u001b[39m], y_pred\u001b[38;5;241m.\u001b[39mshape[\u001b[38;5;241m1\u001b[39m]\n\u001b[0;32m    116\u001b[0m         )\n\u001b[0;32m    117\u001b[0m     )\n\u001b[0;32m    119\u001b[0m n_outputs \u001b[38;5;241m=\u001b[39m y_true\u001b[38;5;241m.\u001b[39mshape[\u001b[38;5;241m1\u001b[39m]\n\u001b[0;32m    120\u001b[0m allowed_multioutput_str \u001b[38;5;241m=\u001b[39m (\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mraw_values\u001b[39m\u001b[38;5;124m\"\u001b[39m, \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124muniform_average\u001b[39m\u001b[38;5;124m\"\u001b[39m, \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mvariance_weighted\u001b[39m\u001b[38;5;124m\"\u001b[39m)\n",
      "\u001b[1;31mValueError\u001b[0m: y_true and y_pred have different number of output (1!=3)"
     ]
    }
   ],
   "source": [
    "model = ARIMAModel(   \n",
    "    file_path=\"../data/HMIS_DATA_CORRECTED_17_21/mh_dist17_21_with_IDs_date_correction.csv\",\n",
    "    value_col=\"I1\",\n",
    "    selected_district=\"THANE\",\n",
    "    test_size=0.2\n",
    ")\n",
    "model.split_data()\n",
    "model.grid_search(pdq_range=(2, 1, 2))\n",
    "model.fit_model()\n",
    "forecast = model.forecast(steps=len(model.test))\n",
    "print(model.evaluate(forecast))\n",
    "model.plot_results(forecast)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3d3d69af",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1fb7a4cd",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "77452024",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8a0b23bb",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "435591ac",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.0"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
